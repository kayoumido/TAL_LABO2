{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c7/HEIG-VD_Logo_96x29_RVB_ROUGE.png\" alt=\"HEIG-VD Logo\" width=\"250\" /> \n",
    "\n",
    "# Cours TAL - Laboratoire 2\n",
    "# Mise en œuvre et évaluation de *POS taggers* pour le français\n",
    "\n",
    "**Objectif**\n",
    "\n",
    "Appliquer des étiqueteurs morphosyntaxiques (POS taggers) disponibles dans NLTK et dans les outils Stanford NLP à des textes français, puis quantifier leurs performances.\n",
    "\n",
    "**Instructions initiales**\n",
    "\n",
    "* Télécharger l'archive `UD_French-GSD-withBlankLines.zip` fournie sur Cyberlearn.\n",
    "* Placer les trois fichiers qu'elle contient dans le même dossier que le notebook.\n",
    "* Ce sont des textes en français annotés avec les POS tags, provenant du projet ([Universal Dependencies](https://github.com/UniversalDependencies/UD_French-GSD)), et légèrement modifiés.\n",
    "  - le fichier `fr-ud-train.conllu3` est destiné à l'entraînement\n",
    "  - le fichier `fr-ud-dev.conllu3` est destiné aux tests préliminaires et aux réglages des paramètres\n",
    "  - le fichier `fr-ud-test.conllu3` est destiné à l'évaluation finale.\n",
    "\n",
    "**Questions préliminaires**\n",
    "\n",
    "* En inspectant les fichiers, veuillez indiquer le numéro de la colonne où se trouvent les mots, et celui de la colonne où se trouvent leur étiquettes morpho-syntaxiques (*POS tags*).\n",
    "* Veuillez chercher sur le Web la liste des *POS tags* du projet Universal Dependencies, avec leurs définitions, et indiquer l'URL ci-dessous.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Réponses: \n",
    "> 1. Les mots se trouve dans 2e colonne et leurs étiquettes se trouvent dans 4e colonnes.\n",
    "> 2. [https://universaldependencies.org/u/pos/](https://universaldependencies.org/u/pos/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Veuillez déterminer et afficher le nombre de tokens de chacun des trois fichiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in fr-ud-test.conllu3: 10298\n",
      "Number of phrases in fr-ud-test.conllu3: 417\n",
      "\n",
      "Number of tokens in fr-ud-dev.conllu3: 36830\n",
      "Number of phrases in fr-ud-dev.conllu3: 1479\n",
      "\n",
      "Number of tokens in fr-ud-train.conllu3: 366371\n",
      "Number of phrases in fr-ud-train.conllu3: 14555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "# since each line of a `conllu3` file corresponds to a single token, \n",
    "# we simply need to count each line in the file to find the number of words in the original text\n",
    "\n",
    "for file in ['fr-ud-test.conllu3', 'fr-ud-dev.conllu3', 'fr-ud-train.conllu3']:\n",
    "    with open(file, 'r', encoding='utf8') as fd:\n",
    "        lines = fd.read().split(\"\\n\")\n",
    "        print(\"Number of tokens in {}: {}\".format(file, len(list(filter(lambda x: x != \"\", lines)))))\n",
    "        print(\"Number of phrases in {}: {}\".format(file, len(list(filter(lambda x: x == \"\", lines)))))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1 : Évaluer le Stanford POS tagger avec les modèles fournis pour le français\n",
    "\n",
    "L'Université de Stanford fournit un étiqueteur morpho-syntaxique (POS tagger) qui utilise l'apprentissage automatique (https://nlp.stanford.edu/software/tagger.html) appelé Maxent Tagger.  Le tagger et ses modèles multilingues peuvent être téléchargés à l'URL ci-dessus (archive ZIP suivant le lien *Download > full Stanford Tagger version 3.9.2*, 130 MB environ).  \n",
    "\n",
    "Pour simplifier, on vous propose de télécharger séparément le programme Java [stanford-postagger.jar](https://drive.switch.ch/index.php/s/hMY6yO7lmoQJuS3) et le modèle français [french-ud.tagger](https://drive.switch.ch/index.php/s/4HSqKRTTTkCgPfB) fournis par l'enseignant (mot de passe = reference).  Enregistrez ces deux fichiers dans le même dossier que ce notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le Maxent Tagger est en Java, et peut être exécuté depuis ce notebook avec un appel Java en ligne de commande.  Pour exécuter une commande système depuis le notebook, ajouter '!' devant (par exemple `! dir` ou `! ls`).  Utilisez la [documentation du Maxent Tagger](https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/tagger/maxent/MaxentTagger.html), et plus précisément la section *Tagging and Testing from the command line*, pour comprendre comment l'invoquer.  Java doit être installé sur votre système, et si nécessaire, exécuter :\n",
    "```python\n",
    "import os\n",
    "java_path = 'C:/Program Files (x86)/Java/jdk1.8.0_20/bin/java.exe'  # votre chemin de java.exe\n",
    "os.environ['JAVA_HOME'] = java_path   # attention aux slash (pas backslash sous Windows)\n",
    "```\n",
    "*Note* : il est également possible d'appeler ce tagger avec des commandes NLTK grâce au module [nltk.tag.stanford](https://www.nltk.org/_modules/nltk/tag/stanford.html) mais la gestion des *paths* entre Java, les classes et les modèles peut être compliquée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "java_path = '/usr/bin/java'\n",
    "os.environ['JAVA_HOME'] = java_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "Appliquez le Maxent Tagger pour étiqueter le fichier `fr-ud-dev.conllu3` et demandez à Maxent Tagger de mesurer la qualité par comparaison à une l'annotation de référence fournie dans le fichier. Quels sont les scores obtenus ?  Quel est le nombre le plus important?  Indiquez ces réponses en commentaires du code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default properties from tagger french-ud.tagger\n",
      "Loading POS tagger from french-ud.tagger ... done [0.6 sec].\n",
      "Tagged 36830 words at 16310.89 words per second.\n",
      "Model french-ud.tagger has xSize=304855, ySize=18, and numFeatures=104853.\n",
      "Results on 1478 sentences and 36830 words, of which 3049 were unknown.\n",
      "Total sentences right: 144 (9.742896%); wrong: 1334 (90.257104%).\n",
      "Total tags right: 32360 (87.863155%); wrong: 4470 (12.136845%).\n",
      "Unknown words right: 2232 (73.204329%); wrong: 817 (26.795671%).\n"
     ]
    }
   ],
   "source": [
    "# Resulats:\n",
    "# Nombre de phrases total correct: 144 (9.742896%); fausse: 1334 (90.257104%).\n",
    "# Nombre de tags total correct: 32360 (87.863155%); fausse: 4470 (12.136845%).\n",
    "# Nombre de mots inconnus total correct: 2232 (73.204329%); fausse: 817 (26.795671%).\n",
    "# \n",
    "# Le nombre le plus important est celui lié au nombre de mots *inconnus* qu'il a pu classifier\n",
    "\n",
    "!java -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.MaxentTagger -model 'french-ud.tagger' -testFile 'format=TSV,wordColumn=1,tagColumn=3,fr-ud-dev.conllu3' -verboseResults false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De même, appliquez le Maxent Tagger pour étiqueter le fichier `fr-ud-test.conllu3` et indiquez la précision du tagger en commentaires du code (#)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default properties from tagger french-ud.tagger\n",
      "Loading POS tagger from french-ud.tagger ... done [0.5 sec].\n",
      "Tagged 10298 words at 11279.30 words per second.\n",
      "Model french-ud.tagger has xSize=304855, ySize=18, and numFeatures=104853.\n",
      "Results on 416 sentences and 10298 words, of which 697 were unknown.\n",
      "Total sentences right: 54 (12.980769%); wrong: 362 (87.019231%).\n",
      "Total tags right: 8960 (87.007186%); wrong: 1338 (12.992814%).\n",
      "Unknown words right: 487 (69.870875%); wrong: 210 (30.129125%).\n"
     ]
    }
   ],
   "source": [
    "# Précisions:\n",
    "# Phrases: ~12%\n",
    "# Tokens: ~87%\n",
    "# Mots inconnus: ~70%\n",
    "!java -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.MaxentTagger -model 'french-ud.tagger' -testFile 'format=TSV,wordColumn=1,tagColumn=3,fr-ud-test.conllu3' -verboseResults false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question subsidiare** : combien de phrases et de mots le tagger trouve-t-il dans les fichiers `fr-ud-dev.conllu3` et `fr-ud-test.conllu3` ?  Comparez avec votre propre estimation du nombre de mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous avons trouver 10298 tokens & 417 phrases dans le fichier `fr-ud-test.conllu3` \n",
    "#  et le tagger lui en a trouvé 10298 tokens & 416 phrases\n",
    "# \n",
    "# Nous avons trouver 36830 tokens & 1479 phrases dans le fichier `fr-ud-tedevst.conllu3` \n",
    "#  et le tagger lui en a trouvé 36830 tokens & 1478 phrases\n",
    "\n",
    "# Nous avons une différence de 1 sur le nombre de phrase qui est \n",
    "#  surement du à une ligne vide supplémentaire à la fin du fichier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2 : Entraîner le Stanford POS tagger pour obtenir de nouveaux modèles\n",
    "\n",
    "Le but de cette partie est d'entraîner le Maxent Tagger sur les données UD en français (`fr-ud-train.conllu3`), puis de comparer le modèle obtenu avec les modèles fournis par Stanford pour le français, testés dans la partie 1A.  \n",
    "\n",
    "Suivre la [documentation de Maxent Tagger](https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/tagger/maxent/MaxentTagger.html) pour l'entraîner sur le fichier `fr-ud-train.conllu3` et le tester sur `fr-ud-test.conllu3`.  Regardez la section *Training from the command line*. \n",
    "\n",
    "La configuration du système pour effectuer l'entraînement est donnée dans un fichier texte, qui peut être produit en suivant la documentation (option `-genprops` pour obtenir un template qui sera édité), soit en s'inspirant du fichier [french-ud.tagger.props](https://drive.switch.ch/index.php/s/gHlam9S74HG2Q4X) accompagnant le modèle `french-ud.tagger` que vous avez utilisé ci-dessus.  Pensez à donner un nouveau nom à votre fichier modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "\n",
    "* Créez un fichier `myFrench-ud.tagger.props` qui aboutit à un bon entraînement.  Vous pourrez expérimenter plusieurs fois et proposer le meilleur fichier.  Citez dans le notebook les paramètres sur lesquels vous avez agi.\n",
    "\n",
    "* Lancez l'entraînement sur le fichier `fr-ud-train.conllu3` (s'il ne tient pas en mémoire, utilisez seulement `fr-ud-dev.conllu3`). Pendant l’entraînement (> 10 minutes, 500 itérations), regardez la suite du travail.\n",
    "\n",
    "* Évaluez votre modèle comme ci-dessus (sur `dev` et sur `test`).  Quel modèle est meilleur, le vôtre ou celui fourni par Stanford ?  Formulez une hypothèse expliquant ce résultat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Sample properties file for maxent tagger. This file is used for three main\r\n",
      "## operations: training, testing, and tagging. It may also be used to dump\r\n",
      "## the contents of a model.\r\n",
      "## To train or test a model, or to tag something, run:\r\n",
      "##   java edu.stanford.nlp.tagger.maxent.MaxentTagger -prop <properties file>\r\n",
      "## Arguments can be overridden on the commandline, e.g.:\r\n",
      "##   java ....MaxentTagger -prop <properties file> -testFile /other/file \r\n",
      "\r\n",
      "# Model file name (created at train time; used at tag and test time)\r\n",
      "# (you can leave this blank and specify it on the commandline with -model)\r\n",
      "model = french-student.tagger\r\n",
      "\r\n",
      "# Path to file to be operated on (trained from, tested against, or tagged)\r\n",
      "# Specify -textFile <filename> to tag text in the given file, -trainFile <filename> to\r\n",
      "# to train a model using data in the given file, or -testFile <filename> to test your\r\n",
      "# model using data in the given file.  Alternatively, you may specify\r\n",
      "# -dump <filename> to dump the parameters stored in a model or \r\n",
      "# -convertToSingleFile <filename> to save an old, multi-file model (specified as -model)\r\n",
      "# to the new single file format.  The new model will be saved in the file filename.\r\n",
      "# If you choose to convert an old file, you must specify \r\n",
      "# the correct 'arch' parameter used to create the original model.\r\n",
      "trainFile = format=TSV,wordColumn=1,tagColumn=3,fr-ud-train.conllu3\r\n",
      "\r\n",
      "# Path to outputFile to write tagged output to.\r\n",
      "# If empty, stdout is used.\r\n",
      "# outputFile = \r\n",
      "\r\n",
      "# Output format. One of: slashTags (default), xml, or tsv\r\n",
      "# outputFormat = slashTags\r\n",
      "\r\n",
      "# Output format options. Comma separated list.\r\n",
      "# currently \"lemmatize\" and \"keepEmptySentences\" are supported.\r\n",
      "# outputFormatOptions = \r\n",
      "\r\n",
      "# Tag separator character that separates word and pos tags\r\n",
      "# (for both training and test data) and used for\r\n",
      "# separating words and tags in slashTags format output.\r\n",
      "# tagSeparator = /\r\n",
      "\r\n",
      "# Encoding format in which files are stored.  If left blank, UTF-8 is assumed.\r\n",
      "# encoding = UTF-8\r\n",
      "\r\n",
      "# A couple flags for controlling the amount of output:\r\n",
      "# - print extra debugging information:\r\n",
      "# verbose = false\r\n",
      "# - print intermediate results:\r\n",
      "# verboseResults = true\r\n",
      "######### parameters for tag and test operations #########\r\n",
      "\r\n",
      "# Class to use for tokenization. Default blank value means Penn Treebank\r\n",
      "# tokenization.  If you'd like to just assume that tokenization has been done,\r\n",
      "# and the input is whitespace-tokenized, use\r\n",
      "# edu.stanford.nlp.process.WhitespaceTokenizer or set tokenize to false.\r\n",
      "# tokenizerFactory = \r\n",
      "\r\n",
      "# Options to the tokenizer.  A comma separated list.\r\n",
      "# This depends on what the tokenizer supports.\r\n",
      "# For PTBTokenizer, you might try options like americanize=false\r\n",
      "# or asciiQuotes (for German!).\r\n",
      "# tokenizerOptions = \r\n",
      "\r\n",
      "# Whether to tokenize text for tag and test operations. Default is true.\r\n",
      "# If false, your text must already be whitespace tokenized.\r\n",
      "# tokenize = true\r\n",
      "\r\n",
      "# Write debugging information (words, top words, unknown words). Useful for\r\n",
      "# error analysis. Default is false.\r\n",
      "# debug = false\r\n",
      "\r\n",
      "# Prefix for debugging output (if debug == true). Default is to use the\r\n",
      "# filename from 'file'\r\n",
      "# debugPrefix = \r\n",
      "\r\n",
      "######### parameters for training  #########\r\n",
      "\r\n",
      "# model architecture: This is one or more comma separated strings, which\r\n",
      "# specify which extractors to use. Some of them take one or more integer\r\n",
      "# or string \r\n",
      "# (file path) arguments in parentheses, written as m, n, and s below:\r\n",
      "# 'left3words', 'left5words', 'bidirectional', 'bidirectional5words',\r\n",
      "# 'generic', 'sighan2005', 'german', 'words(m,n)', 'wordshapes(m,n)',\r\n",
      "# 'biwords(m,n)', 'lowercasewords(m,n)', 'vbn(n)', distsimconjunction(s,m,n)',\r\n",
      "# 'naacl2003unknowns', 'naacl2003conjunctions', 'distsim(s,m,n)',\r\n",
      "# 'suffix(n)', 'prefix(n)', 'prefixsuffix(n)', 'capitalizationsuffix(n)',\r\n",
      "# 'wordshapes(m,n)', 'unicodeshapes(m,n)', 'unicodeshapeconjunction(m,n)',\r\n",
      "# 'lctagfeatures', 'order(k)', 'chinesedictionaryfeatures(s)'.\r\n",
      "# These keywords determines the features extracted.  'generic' is language independent.\r\n",
      "# distsim: Distributional similarity classes can be an added source of information\r\n",
      "# about your words. An English distsim file is included, or you can use your own.\r\n",
      "# arch = left5words # 95.377743%, 95.400489%\r\n",
      "arch = bidirectional5words\r\n",
      "\r\n",
      "# 'wordFunction'.  A function applied to the text before training or tagging.\r\n",
      "# For example, edu.stanford.nlp.util.LowercaseFunction\r\n",
      "# This function turns all the words into lowercase\r\n",
      "# The function must implement java.util.function.Function<String, String>\r\n",
      "# Blank means no preprocessing function\r\n",
      "# wordFunction = \r\n",
      "\r\n",
      "# 'language'.  This is really the tag set which is used for the\r\n",
      "# list of open-class tags, and perhaps deterministic  tag\r\n",
      "# expansion). Currently we have 'english', 'arabic', 'german', 'chinese'\r\n",
      "# or 'polish' predefined. For your own language, you can specify \r\n",
      "# the same information via openClassTags or closedClassTags below\r\n",
      "# (only ONE of these three options may be specified). \r\n",
      "# 'english' means UPenn English treebank tags. 'german' is STTS\r\n",
      "# 'chinese' is CTB, and Arabic is an expanded Bies mapping from the ATB\r\n",
      "# 'polish' means some tags that some guy on the internet once used. \r\n",
      "# See the TTags class for more information.\r\n",
      "lang = english\r\n",
      "\r\n",
      "# a space-delimited list of open-class parts of speech\r\n",
      "# alternatively, you can specify language above to use a pre-defined list or specify the closed class tags (below)\r\n",
      "# openClassTags = \r\n",
      "\r\n",
      "# a space-delimited list of closed-class parts of speech\r\n",
      "# alternatively, you can specify language above to use a pre-defined list or specify the open class tags (above)\r\n",
      "# closedClassTags = \r\n",
      "\r\n",
      "# A boolean indicating whether you would like the trained model to set POS tags as closed\r\n",
      "# based on their frequency in training; default is false.  The frequency threshold can be set below. \r\n",
      "# This option is ignored if any of {openClassTags, closedClassTags, lang} are specified.\r\n",
      "# learnClosedClassTags = \r\n",
      "\r\n",
      "# Used only if learnClosedClassTags=true.  Tags that have fewer tokens than this threshold are\r\n",
      "# considered closed in the trained model.\r\n",
      "# closedClassTagThreshold = \r\n",
      "\r\n",
      "# search method for optimization. Normally use the default 'qn'. choices: 'qn' (quasi-Newton),\r\n",
      "# 'cg' (conjugate gradient, 'owlqn' (L1 regularization) or 'iis' (improved iterative scaling)\r\n",
      "# search = qn\r\n",
      "\r\n",
      "# for conjugate gradient or quasi-Newton search, sigma-squared smoothing/regularization\r\n",
      "# parameter. if left blank, the default is 0.5, which is usually okay\r\n",
      "# sigmaSquared = 0.5\r\n",
      "\r\n",
      "# for OWLQN search, regularization\r\n",
      "# parameter. if left blank, the default is 1.0, which is usually okay\r\n",
      "# regL1 = 1.0\r\n",
      "\r\n",
      "# For improved iterative scaling, the number of iterations, otherwise ignored\r\n",
      "# iterations = 100\r\n",
      "\r\n",
      "# rare word threshold. words that occur less than this number of\r\n",
      "# times are considered rare words.\r\n",
      "# rareWordThresh = 5\r\n",
      "\r\n",
      "# minimum feature threshold. features whose history appears less\r\n",
      "# than this number of times are ignored.\r\n",
      "# minFeatureThresh = 5\r\n",
      "\r\n",
      "# current word feature threshold. words that occur more than this\r\n",
      "# number of times will generate features with all of their occurring\r\n",
      "# tags.\r\n",
      "# curWordMinFeatureThresh = 2\r\n",
      "\r\n",
      "# rare word minimum feature threshold. features of rare words whose histories\r\n",
      "# appear less than this times will be ignored.\r\n",
      "# rareWordMinFeatureThresh = 10\r\n",
      "\r\n",
      "# very common word threshold. words that occur more than this number of\r\n",
      "# times will form an equivalence class by themselves. ignored unless\r\n",
      "# you are using equivalence classes.\r\n",
      "# veryCommonWordThresh = 250\r\n",
      "\r\n",
      "# sgml = \r\n",
      "# tagInside = \r\n",
      "\r\n",
      "# testFile and textFile can use multiple threads to process text.\r\n",
      "# nthreads = 1\r\n"
     ]
    }
   ],
   "source": [
    "# !java -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.MaxentTagger \\\n",
    "#     -genprops > french-student.props\n",
    "!cat french-student.props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## tagger training invoked at Fri Mar 19 16:02:25 UTC 2021 with arguments:\n",
      "                   model = french-student.tagger\n",
      "                    arch = left5words\n",
      "            wordFunction = \n",
      "               trainFile = format=TSV,wordColumn=1,tagColumn=3,fr-ud-train.conllu3\n",
      "         closedClassTags = \n",
      " closedClassTagThreshold = 40\n",
      " curWordMinFeatureThresh = 2\n",
      "                   debug = false\n",
      "             debugPrefix = \n",
      "            tagSeparator = /\n",
      "                encoding = UTF-8\n",
      "              iterations = 500\n",
      "                    lang = english\n",
      "    learnClosedClassTags = false\n",
      "        minFeatureThresh = 5\n",
      "           openClassTags = \n",
      "rareWordMinFeatureThresh = 10\n",
      "          rareWordThresh = 5\n",
      "                  search = qn\n",
      "                    sgml = false\n",
      "            sigmaSquared = 0.5\n",
      "                   regL1 = 1.0\n",
      "               tagInside = \n",
      "                tokenize = true\n",
      "        tokenizerFactory = \n",
      "        tokenizerOptions = \n",
      "                 verbose = false\n",
      "          verboseResults = true\n",
      "    veryCommonWordThresh = 250\n",
      "                xmlInput = \n",
      "              outputFile = \n",
      "            outputFormat = slashTags\n",
      "     outputFormatOptions = \n",
      "                nthreads = 1\n",
      "TaggerExperiments: adding word/tags\n",
      "Loading tagged words from fr-ud-train.conllu3\n",
      "Read 366371 words from fr-ud-train.conllu3 [done].\n",
      "Read 14554 sentences, min 2 words, max 404 words.\n",
      "Featurizing tagged data tokens...\n",
      "Featurized 380925 data tokens [done].\n",
      "xSize [num Phi templates] = 358953; ySize [num classes] = 19\n",
      "Hashing histories ...\n",
      "Hashed 358953 histories.\n",
      "Hashing populated histories ...\n",
      "Hashed populated histories.\n",
      "TaggerExperiments.getFeaturesNew: initializing fnumArr.\n",
      "  length of sTemplates keys: 355362\n",
      "getFeaturesNew adding features ...\n",
      "  total feats: 355362, populated: 139746\n",
      "  Max features per x,y pair: 7\n",
      "  Max non-zero y values for an x: 19\n",
      "  Number of non-zero feature x,y pairs: 6656899\n",
      "  Number of zero feature x,y pairs: 163208\n",
      "end getFeaturesNew.\n",
      "Samples from format=TSV,wordColumn=1,tagColumn=3,fr-ud-train.conllu3\n",
      "Number of features: 139746\n",
      "Tag set: [AUX, PRON, CCONJ, PROPN, SYM, ADJ, NUM, SCONJ, ADP, DET, ADV, PUNCT, .$$., PART, VERB, X, INTJ, NOUN, _]\n",
      " pcond initialized \n",
      " zlambda initialized \n",
      " ftildeArr initialized \n",
      "QNMinimizer called on double function of 139746 variables, using M = 10.\n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 0: neg. log cond. likelihood = 1121610.4181363843 [1 calls to valueAt]\n",
      "               An explanation of the output:\n",
      "Iter           The number of iterations\n",
      "evals          The number of function evaluations\n",
      "SCALING        <D> Diagonal scaling was used; <I> Scaled Identity\n",
      "LINESEARCH     [## M steplength]  Minpack linesearch\n",
      "                   1-Function value was too high\n",
      "                   2-Value ok, gradient positive, positive curvature\n",
      "                   3-Value ok, gradient negative, positive curvature\n",
      "                   4-Value ok, gradient negative, negative curvature\n",
      "               [.. B]  Backtracking\n",
      "VALUE          The current function value\n",
      "TIME           Total elapsed time\n",
      "|GNORM|        The current norm of the gradient\n",
      "{RELNORM}      The ratio of the current to initial gradient norms\n",
      "AVEIMPROVE     The average improvement / current value\n",
      "EVALSCORE      The last available eval score\n",
      " \n",
      "Iter ## evals ## <SCALING> [LINESEARCH] VALUE TIME |GNORM| {RELNORM} AVEIMPROVE EVALSCORE\n",
      "\n",
      "lambda 159 too big: 236.08947368398896\n",
      "lambda 1016 too big: 275.99473684198864\n",
      "lambda 1791 too big: 503.4999999998446\n",
      "lambda 3375 too big: 508.694736841707\n",
      "lambda 3997 too big: 450.3263157892915\n",
      "lambda 4604 too big: 1302.1947368433962\n",
      "lambda 4639 too big: 322.9894736841238\n",
      "lambda 7768 too big: 370.02105263152896\n",
      "lambda 10587 too big: 370.0210526315396\n",
      "lambda 10631 too big: 2588.494736845069\n",
      "lambda 14348 too big: 261.39473684183935\n",
      "lambda 14873 too big: -293.2052631579895\n",
      "lambda 14878 too big: -203.6684210524915\n",
      "lambda 15031 too big: -223.46842105254183\n",
      "lambda 15041 too big: -300.60526315800956\n",
      "lambda 18574 too big: 270.02631578937735\n",
      "lambda 21565 too big: -287.1631578948156\n",
      "lambda 21651 too big: 463.6947368418885\n",
      "lambda 22114 too big: 544.6157894733569\n",
      "lambda 24029 too big: 268.4210526314361\n",
      "lambda 24041 too big: 1378.8000000004358\n",
      "lambda 24458 too big: -350.24736842129914\n",
      "lambda 25773 too big: 253.00526315762536\n",
      "lambda 25810 too big: 1068.6315789504267\n",
      "lambda 25813 too big: 538.9315789468138\n",
      "lambda 25836 too big: 478.37368421011155\n",
      "lambda 25842 too big: -213.90526315777998\n",
      "lambda 25845 too big: -259.70526315789533\n",
      "lambda 25849 too big: -247.5052631578592\n",
      "lambda 25995 too big: -272.2052631579336\n",
      "lambda 27119 too big: 269.6421052631168\n",
      "lambda 27550 too big: 270.4421052631193\n",
      "lambda 28259 too big: -218.16842105252726\n",
      "lambda 28387 too big: -298.3052631580032\n",
      "lambda 28388 too big: -292.80526315798846\n",
      "lambda 28778 too big: 1150.5263157912486\n",
      "lambda 30695 too big: 402.9631578946503\n",
      "lambda 30850 too big: 487.7947368417835\n",
      "lambda 33002 too big: -262.7631578947523\n",
      "lambda 34568 too big: 539.7263157893218\n",
      "lambda 34673 too big: -205.62631578933724\n",
      "lambda 35011 too big: 440.88421052612904\n",
      "lambda 35470 too big: 572.4105263156426\n",
      "lambda 36028 too big: 297.71052631569773\n",
      "lambda 36071 too big: -263.24736842107103\n",
      "lambda 36741 too big: 1362.7000000008402\n",
      "lambda 37851 too big: 920.1421052637957\n",
      "lambda 37863 too big: 1286.0947368434563\n",
      "lambda 39182 too big: 322.8789473682777\n",
      "lambda 40559 too big: -347.0473684212902\n",
      "lambda 40642 too big: -317.9473684212119\n",
      "lambda 41506 too big: 520.431578947207\n",
      "lambda 41617 too big: 747.4631578946173\n",
      "lambda 41814 too big: 3982.7368421069696\n",
      "lambda 42072 too big: 834.3578947391002\n",
      "lambda 42166 too big: 346.22631578939485\n",
      "lambda 44806 too big: 269.6421052631275\n",
      "lambda 45738 too big: 561.4315789470595\n",
      "lambda 46829 too big: 520.0052631577756\n",
      "lambda 47369 too big: 1158.2210526325216\n",
      "lambda 47396 too big: 816.2105263164476\n",
      "lambda 47633 too big: 227.19999999986308\n",
      "lambda 48730 too big: 219.16842105251573\n",
      "lambda 50223 too big: 328.61578947364075\n",
      "lambda 50944 too big: 863.6000000007537\n",
      "lambda 51926 too big: -204.12631578933582\n",
      "lambda 52675 too big: 214.6210526315276\n",
      "lambda 53541 too big: -339.74736842127226\n",
      "lambda 54880 too big: 240.5157894735793\n",
      "lambda 55934 too big: 213.0368421045037\n",
      "lambda 55935 too big: 275.20526315785827\n",
      "lambda 57190 too big: 338.47368421047827\n",
      "lambda 59736 too big: -271.36315789477504\n",
      "lambda 60055 too big: 432.72631578938837\n",
      "lambda 60255 too big: 2225.5263157904756\n",
      "lambda 60821 too big: 408.7736842104521\n",
      "lambda 60985 too big: 209.63684210520378\n",
      "lambda 62789 too big: 370.02105263154016\n",
      "lambda 62999 too big: 872.0736842126412\n",
      "lambda 63353 too big: 287.1894736841824\n",
      "lambda 63826 too big: 426.4315789472079\n",
      "lambda 63845 too big: 621.957894736468\n",
      "lambda 64095 too big: -287.5631578948167\n",
      "lambda 66807 too big: -224.56842105254498\n",
      "lambda 66824 too big: 426.9789473683396\n",
      "lambda 68726 too big: 463.6999999997833\n",
      "lambda 69914 too big: -213.84736842090643\n",
      "lambda 69918 too big: 706.3526315818442\n",
      "lambda 69920 too big: 1610.4526315833637\n",
      "lambda 70751 too big: 643.7105263156698\n",
      "lambda 70783 too big: 796.421052632105\n",
      "lambda 71320 too big: 424.7052631577968\n",
      "lambda 72015 too big: 636.4947368418466\n",
      "lambda 73170 too big: 961.952631583701\n",
      "lambda 74200 too big: 325.62631578914375\n",
      "lambda 75063 too big: 462.79473684134575\n",
      "lambda 76667 too big: 680.1157894735927\n",
      "lambda 78135 too big: 506.27368421042195\n",
      "lambda 78140 too big: 1271.2736842109832\n",
      "lambda 78822 too big: 274.1157894736523\n",
      "lambda 80757 too big: 672.715789473413\n",
      "lambda 81407 too big: -287.3631578948161\n",
      "lambda 82367 too big: 225.2947368417681\n",
      "lambda 82408 too big: 237.8947368418957\n",
      "lambda 82918 too big: 416.19999999985976\n",
      "lambda 83790 too big: 253.2157894735741\n",
      "lambda 84387 too big: -298.7052631580043\n",
      "lambda 84452 too big: -223.6684210525424\n",
      "lambda 86176 too big: -223.06842105254066\n",
      "lambda 86438 too big: 200.8421052631509\n",
      "lambda 87590 too big: 291.605263157686\n",
      "lambda 87617 too big: 232.67368421036372\n",
      "lambda 88324 too big: 275.37368421035416\n",
      "lambda 88350 too big: 284.405263157687\n",
      "lambda 90801 too big: 1580.589473685284\n",
      "lambda 90834 too big: 1273.0736842113702\n",
      "lambda 90854 too big: 210.2210526315556\n",
      "lambda 90865 too big: 209.46315789471407\n",
      "lambda 91764 too big: 241.98947368418118\n",
      "lambda 91927 too big: 930.5263157912874\n",
      "lambda 91979 too big: 364.80526315759107\n",
      "lambda 92029 too big: 697.2947368441763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda 92880 too big: 235.42631578917732\n",
      "lambda 93500 too big: 668.8736842103317\n",
      "lambda 95828 too big: 205.16842105251445\n",
      "lambda 98808 too big: 257.5736842103261\n",
      "lambda 99411 too big: 357.2947368416993\n",
      "lambda 100570 too big: 227.19473684196834\n",
      "lambda 100767 too big: 543.1842105261215\n",
      "lambda 104199 too big: 236.27368421050267\n",
      "lambda 106377 too big: -287.3631578948161\n",
      "lambda 106378 too big: -233.36315789466354\n",
      "lambda 108262 too big: 240.97368421048066\n",
      "lambda 109404 too big: 463.6999999997833\n",
      "lambda 109800 too big: 931.9315789490615\n",
      "lambda 109932 too big: 239.0210526315451\n",
      "lambda 110183 too big: 214.6157894735961\n",
      "lambda 112131 too big: -349.0473684212958\n",
      "lambda 112367 too big: -299.4052631580062\n",
      "lambda 113674 too big: -345.6473684212864\n",
      "lambda 115482 too big: 445.3999999997692\n",
      "lambda 118577 too big: -279.9052631579552\n",
      "lambda 118657 too big: 478.1052631575651\n",
      "lambda 118683 too big: 468.1315789467851\n",
      "lambda 119206 too big: 1232.073684212822\n",
      "lambda 119572 too big: 202.53157894702596\n",
      "lambda 119821 too big: 248.4736842103711\n",
      "lambda 119849 too big: 363.1947368418554\n",
      "lambda 120594 too big: -286.0631578948126\n",
      "lambda 121481 too big: -205.22631578933607\n",
      "lambda 122342 too big: 924.442105263922\n",
      "lambda 122778 too big: -287.76315789481714\n",
      "lambda 122779 too big: -282.1631578948024\n",
      "lambda 124507 too big: 248.8736842105035\n",
      "lambda 127160 too big: 1378.7947368425412\n",
      "lambda 127278 too big: 733.2263157894022\n",
      "lambda 127298 too big: 325.5157894735599\n",
      "lambda 128645 too big: 244.71578947361155\n",
      "lambda 130623 too big: 227.19999999986308\n",
      "lambda 134439 too big: 465.49473684183135\n",
      "lambda 134468 too big: 409.5736842103191\n",
      "lambda 134621 too big: -267.0473684210795\n",
      "lambda 134708 too big: 2090.4315789487823\n",
      "lambda 135504 too big: -286.7631578948146\n",
      "lambda 135724 too big: 474.33684210512547\n",
      "lambda 138874 too big: 254.49999999982762\n",
      "lambda 139306 too big: -247.16315789470474\n",
      "lambda 4604 too big: 282.97847978268464\n",
      "lambda 10631 too big: 562.502892104676\n",
      "lambda 24041 too big: 299.6254837201138\n",
      "lambda 25810 too big: 232.22313153576255\n",
      "lambda 28778 too big: 250.01958507511193\n",
      "lambda 36741 too big: 296.12681075248173\n",
      "lambda 37863 too big: 279.4798068149777\n",
      "lambda 41814 too big: 865.4840824237324\n",
      "lambda 47369 too big: 251.69171971984989\n",
      "lambda 60255 too big: 483.62663105624694\n",
      "lambda 69920 too big: 349.9656576344234\n",
      "lambda 73170 too big: 209.04084896577584\n",
      "lambda 78140 too big: 276.2590604672517\n",
      "lambda 90801 too big: 343.476128238848\n",
      "lambda 90834 too big: 276.65021645130446\n",
      "lambda 91927 too big: 202.2116314789467\n",
      "lambda 109800 too big: 202.51700764184343\n",
      "lambda 119206 too big: 267.74055237233307\n",
      "lambda 122342 too big: 200.88947850366657\n",
      "lambda 127160 too big: 299.6243399891665\n",
      "lambda 134708 too big: 454.26934510163346\n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 1: neg. log cond. likelihood = 769121.2832768374 [4 calls to valueAt]\n",
      "Iter 1 evals 1 <D> [11M 4.960E-5] 7.691E5 8.15s |5.309E4| {5.626E-1} 0.000E0 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 2: neg. log cond. likelihood = 524007.4375414458 [5 calls to valueAt]\n",
      "Iter 2 evals 4 <D> [M 1.000E0] 5.240E5 11.01s |2.940E4| {3.115E-1} 2.339E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 3: neg. log cond. likelihood = 438482.4736939849 [6 calls to valueAt]\n",
      "Iter 3 evals 5 <D> [M 1.000E0] 4.385E5 13.91s |2.387E4| {2.530E-1} 2.514E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 4: neg. log cond. likelihood = 370717.1586122929 [7 calls to valueAt]\n",
      "Iter 4 evals 6 <D> [M 1.000E0] 3.707E5 16.76s |2.587E4| {2.742E-1} 2.687E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 5: neg. log cond. likelihood = 328782.12425561214 [8 calls to valueAt]\n",
      "Iter 5 evals 7 <D> [M 1.000E0] 3.288E5 19.62s |1.697E4| {1.798E-1} 2.679E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 6: neg. log cond. likelihood = 300829.102781632 [9 calls to valueAt]\n",
      "Iter 6 evals 8 <D> [M 1.000E0] 3.008E5 22.45s |1.192E4| {1.263E-1} 2.594E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 7: neg. log cond. likelihood = 265674.35941434815 [10 calls to valueAt]\n",
      "Iter 7 evals 9 <D> [M 1.000E0] 2.657E5 25.25s |1.107E4| {1.173E-1} 2.707E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 8: neg. log cond. likelihood = 246120.27081283616 [11 calls to valueAt]\n",
      "Iter 8 evals 10 <D> [M 1.000E0] 2.461E5 28.07s |1.087E4| {1.152E-1} 2.656E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 9: neg. log cond. likelihood = 227779.83910205017 [12 calls to valueAt]\n",
      "Iter 9 evals 11 <D> [M 1.000E0] 2.278E5 30.88s |7.129E3| {7.555E-2} 2.641E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 10: neg. log cond. likelihood = 214517.16713116894 [13 calls to valueAt]\n",
      "Iter 10 evals 12 <D> [M 1.000E0] 2.145E5 33.72s |8.526E3| {9.035E-2} 2.585E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 11: neg. log cond. likelihood = 203676.42462892924 [14 calls to valueAt]\n",
      "Iter 11 evals 13 <D> [M 1.000E0] 2.037E5 36.54s |9.961E3| {1.056E-1} 1.573E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 12: neg. log cond. likelihood = 194043.1350539348 [15 calls to valueAt]\n",
      "Iter 12 evals 14 <D> [M 1.000E0] 1.940E5 39.41s |8.000E3| {8.478E-2} 1.260E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 13: neg. log cond. likelihood = 186344.02476675608 [16 calls to valueAt]\n",
      "Iter 13 evals 15 <D> [M 1.000E0] 1.863E5 42.28s |6.341E3| {6.720E-2} 9.894E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 14: neg. log cond. likelihood = 178136.78830999648 [17 calls to valueAt]\n",
      "Iter 14 evals 16 <D> [M 1.000E0] 1.781E5 45.17s |5.193E3| {5.504E-2} 8.457E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 15: neg. log cond. likelihood = 167879.6316657476 [18 calls to valueAt]\n",
      "Iter 15 evals 17 <D> [M 1.000E0] 1.679E5 48.02s |3.660E3| {3.879E-2} 7.919E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 16: neg. log cond. likelihood = 160676.68191991537 [19 calls to valueAt]\n",
      "Iter 16 evals 18 <D> [M 1.000E0] 1.607E5 50.88s |5.675E3| {6.014E-2} 6.535E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 17: neg. log cond. likelihood = 156159.49009341127 [20 calls to valueAt]\n",
      "Iter 17 evals 19 <D> [M 1.000E0] 1.562E5 53.74s |7.396E3| {7.838E-2} 5.761E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 18: neg. log cond. likelihood = 150430.27376265742 [21 calls to valueAt]\n",
      "Iter 18 evals 20 <D> [M 1.000E0] 1.504E5 56.80s |4.915E3| {5.209E-2} 5.142E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 19: neg. log cond. likelihood = 146274.90294505184 [22 calls to valueAt]\n",
      "Iter 19 evals 21 <D> [M 1.000E0] 1.463E5 60.19s |2.310E3| {2.448E-2} 4.665E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 20: neg. log cond. likelihood = 141535.1948437429 [23 calls to valueAt]\n",
      "Iter 20 evals 22 <D> [M 1.000E0] 1.415E5 63.62s |2.131E3| {2.258E-2} 4.391E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 21: neg. log cond. likelihood = 137437.76132995475 [24 calls to valueAt]\n",
      "Iter 21 evals 23 <D> [M 1.000E0] 1.374E5 66.67s |4.312E3| {4.570E-2} 4.119E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 22: neg. log cond. likelihood = 133492.39253450432 [25 calls to valueAt]\n",
      "Iter 22 evals 24 <D> [M 1.000E0] 1.335E5 69.55s |3.018E3| {3.198E-2} 3.959E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 23: neg. log cond. likelihood = 132121.26492525561 [26 calls to valueAt]\n",
      "Iter 23 evals 25 <D> [M 1.000E0] 1.321E5 72.68s |5.909E3| {6.262E-2} 3.483E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 24: neg. log cond. likelihood = 128590.01483485772 [27 calls to valueAt]\n",
      "Iter 24 evals 26 <D> [M 1.000E0] 1.286E5 75.99s |2.805E3| {2.973E-2} 3.055E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 25: neg. log cond. likelihood = 126584.27613209706 [28 calls to valueAt]\n",
      "Iter 25 evals 27 <D> [M 1.000E0] 1.266E5 79.65s |3.104E3| {3.289E-2} 2.693E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 26: neg. log cond. likelihood = 124720.49826040657 [29 calls to valueAt]\n",
      "Iter 26 evals 28 <D> [M 1.000E0] 1.247E5 82.65s |2.770E3| {2.935E-2} 2.521E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 27: neg. log cond. likelihood = 122397.39014318494 [30 calls to valueAt]\n",
      "Iter 27 evals 29 <D> [M 1.000E0] 1.224E5 85.76s |2.766E3| {2.931E-2} 2.290E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 28: neg. log cond. likelihood = 120627.774724574 [31 calls to valueAt]\n",
      "Iter 28 evals 30 <D> [M 1.000E0] 1.206E5 88.69s |2.721E3| {2.884E-2} 2.126E-2 - \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 29: neg. log cond. likelihood = 118915.07064733419 [32 calls to valueAt]\n",
      "Iter 29 evals 31 <D> [M 1.000E0] 1.189E5 91.59s |1.978E3| {2.096E-2} 1.902E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 30: neg. log cond. likelihood = 116993.21572293885 [33 calls to valueAt]\n",
      "Checking model correctness; x size 358953 , ysize 19\n",
      "Constraint 55336 not satisfied emp 0.0095 exp 0.0107 diff 0.0012 lambda 2.0856\n",
      "Constraint 75063 not satisfied emp 0.02 exp 0.0219 diff 0.0018 lambda 3.3457\n",
      "Constraint 92029 not satisfied emp 0.0262 exp 0.0252 diff 0.001 lambda 3.1428\n",
      "Constraint 92880 not satisfied emp 0.0095 exp 0.0106 diff 0.0011 lambda 1.2818\n",
      "Iter 30 evals 32 <D> [M 1.000E0] 1.170E5 94.46s |1.996E3| {2.115E-2} 1.747E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 31: neg. log cond. likelihood = 115597.27891711425 [34 calls to valueAt]\n",
      "Iter 31 evals 33 <D> [M 1.000E0] 1.156E5 98.04s |2.706E3| {2.868E-2} 1.548E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 32: neg. log cond. likelihood = 114267.1151095759 [35 calls to valueAt]\n",
      "Iter 32 evals 34 <D> [M 1.000E0] 1.143E5 100.88s |1.461E3| {1.548E-2} 1.562E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 33: neg. log cond. likelihood = 113088.28193658737 [36 calls to valueAt]\n",
      "Iter 33 evals 35 <D> [M 1.000E0] 1.131E5 103.75s |1.260E3| {1.336E-2} 1.371E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 34: neg. log cond. likelihood = 111580.71124941754 [37 calls to valueAt]\n",
      "Iter 34 evals 36 <D> [M 1.000E0] 1.116E5 106.65s |2.013E3| {2.133E-2} 1.345E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 35: neg. log cond. likelihood = 110449.90220978616 [38 calls to valueAt]\n",
      "Iter 35 evals 37 <D> [M 1.000E0] 1.104E5 109.53s |1.570E3| {1.664E-2} 1.292E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 36: neg. log cond. likelihood = 109431.25296176724 [39 calls to valueAt]\n",
      "Iter 36 evals 38 <D> [M 1.000E0] 1.094E5 112.40s |1.330E3| {1.409E-2} 1.185E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 37: neg. log cond. likelihood = 108854.05148108843 [40 calls to valueAt]\n",
      "Iter 37 evals 39 <D> [M 1.000E0] 1.089E5 115.33s |3.389E3| {3.592E-2} 1.082E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 38: neg. log cond. likelihood = 107879.33129499364 [41 calls to valueAt]\n",
      "Iter 38 evals 40 <D> [M 1.000E0] 1.079E5 118.19s |1.940E3| {2.056E-2} 1.023E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 39: neg. log cond. likelihood = 107400.06785153477 [42 calls to valueAt]\n",
      "Iter 39 evals 41 <D> [M 1.000E0] 1.074E5 121.04s |1.411E3| {1.495E-2} 8.932E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 40: neg. log cond. likelihood = 106895.73315155639 [43 calls to valueAt]\n",
      "Iter 40 evals 42 <D> [M 1.000E0] 1.069E5 123.87s |9.516E2| {1.008E-2} 8.140E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 41: neg. log cond. likelihood = 106174.56294330582 [44 calls to valueAt]\n",
      "Iter 41 evals 43 <D> [M 1.000E0] 1.062E5 126.72s |1.012E3| {1.072E-2} 7.622E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 42: neg. log cond. likelihood = 105653.60755075993 [45 calls to valueAt]\n",
      "Iter 42 evals 44 <D> [M 1.000E0] 1.057E5 130.09s |1.097E3| {1.162E-2} 7.037E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 43: neg. log cond. likelihood = 105151.42693837552 [46 calls to valueAt]\n",
      "Iter 43 evals 45 <D> [M 1.000E0] 1.052E5 133.00s |8.900E2| {9.431E-3} 6.114E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 44: neg. log cond. likelihood = 104963.13165213236 [47 calls to valueAt]\n",
      "Iter 44 evals 46 <D> [M 1.000E0] 1.050E5 135.87s |1.989E3| {2.108E-2} 5.227E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 45: neg. log cond. likelihood = 104355.99778011012 [48 calls to valueAt]\n",
      "Iter 45 evals 47 <D> [M 1.000E0] 1.044E5 138.65s |6.636E2| {7.032E-3} 4.863E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 46: neg. log cond. likelihood = 104072.81150643238 [49 calls to valueAt]\n",
      "Iter 46 evals 48 <D> [M 1.000E0] 1.041E5 141.47s |6.872E2| {7.283E-3} 4.594E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 47: neg. log cond. likelihood = 103766.5287825409 [50 calls to valueAt]\n",
      "Iter 47 evals 49 <D> [M 1.000E0] 1.038E5 144.25s |1.374E3| {1.456E-2} 3.964E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 48: neg. log cond. likelihood = 103494.15909157322 [51 calls to valueAt]\n",
      "Iter 48 evals 50 <D> [M 1.000E0] 1.035E5 147.09s |7.416E2| {7.859E-3} 3.774E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 49: neg. log cond. likelihood = 103267.62186675628 [52 calls to valueAt]\n",
      "Iter 49 evals 51 <D> [M 1.000E0] 1.033E5 149.90s |4.730E2| {5.012E-3} 3.513E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 50: neg. log cond. likelihood = 103046.5586985652 [53 calls to valueAt]\n",
      "Iter 50 evals 52 <D> [M 1.000E0] 1.030E5 152.77s |6.313E2| {6.690E-3} 3.036E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 51: neg. log cond. likelihood = 102843.42807608143 [54 calls to valueAt]\n",
      "Iter 51 evals 53 <D> [M 1.000E0] 1.028E5 155.64s |6.837E2| {7.245E-3} 2.732E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 52: neg. log cond. likelihood = 102668.50056068417 [55 calls to valueAt]\n",
      "Iter 52 evals 54 <D> [M 1.000E0] 1.027E5 158.49s |5.469E2| {5.796E-3} 2.418E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 53: neg. log cond. likelihood = 102521.44447849396 [56 calls to valueAt]\n",
      "Iter 53 evals 55 <D> [M 1.000E0] 1.025E5 161.33s |7.032E2| {7.452E-3} 2.382E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 54: neg. log cond. likelihood = 102481.39791850674 [57 calls to valueAt]\n",
      "Iter 54 evals 56 <D> [M 1.000E0] 1.025E5 164.16s |1.522E3| {1.613E-2} 1.829E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 55: neg. log cond. likelihood = 102323.58568003992 [58 calls to valueAt]\n",
      "Iter 55 evals 57 <D> [M 1.000E0] 1.023E5 167.03s |3.136E2| {3.324E-3} 1.710E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 56: neg. log cond. likelihood = 102253.47950608323 [59 calls to valueAt]\n",
      "Iter 56 evals 58 <D> [M 1.000E0] 1.023E5 169.89s |2.543E2| {2.695E-3} 1.480E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 57: neg. log cond. likelihood = 102149.23774272452 [60 calls to valueAt]\n",
      "Iter 57 evals 59 <D> [M 1.000E0] 1.021E5 172.75s |4.885E2| {5.176E-3} 1.317E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 58: neg. log cond. likelihood = 102087.27840530137 [61 calls to valueAt]\n",
      "Iter 58 evals 60 <D> [M 1.000E0] 1.021E5 175.64s |7.239E2| {7.672E-3} 1.156E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 59: neg. log cond. likelihood = 102001.26916410374 [62 calls to valueAt]\n",
      "Iter 59 evals 61 <D> [M 1.000E0] 1.020E5 178.54s |3.366E2| {3.567E-3} 1.025E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 60: neg. log cond. likelihood = 101961.94698818299 [63 calls to valueAt]\n",
      "Checking model correctness; x size 358953 , ysize 19\n",
      "Iter 60 evals 62 <D> [M 1.000E0] 1.020E5 181.41s |5.444E2| {5.769E-3} 8.645E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 61: neg. log cond. likelihood = 101906.63811722132 [64 calls to valueAt]\n",
      "Iter 61 evals 63 <D> [M 1.000E0] 1.019E5 184.98s |2.769E2| {2.934E-3} 7.476E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 62: neg. log cond. likelihood = 101879.2890215471 [65 calls to valueAt]\n",
      "Iter 62 evals 64 <D> [M 1.000E0] 1.019E5 187.87s |4.434E2| {4.699E-3} 6.303E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 63: neg. log cond. likelihood = 101834.44761029992 [66 calls to valueAt]\n",
      "Iter 63 evals 65 <D> [M 1.000E0] 1.018E5 190.75s |1.686E2| {1.786E-3} 6.353E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 64: neg. log cond. likelihood = 101795.10999705043 [67 calls to valueAt]\n",
      "Iter 64 evals 66 <D> [M 1.000E0] 1.018E5 193.59s |2.479E2| {2.627E-3} 5.192E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 65: neg. log cond. likelihood = 101759.06797438282 [68 calls to valueAt]\n",
      "Iter 65 evals 67 <D> [M 1.000E0] 1.018E5 196.42s |4.842E2| {5.132E-3} 4.859E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 66: neg. log cond. likelihood = 101740.86190905372 [69 calls to valueAt]\n",
      "Iter 66 evals 68 <D> [M 1.000E0] 1.017E5 199.22s |4.627E2| {4.903E-3} 4.014E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 67: neg. log cond. likelihood = 101708.39916914087 [70 calls to valueAt]\n",
      "Iter 67 evals 69 <D> [M 1.000E0] 1.017E5 202.11s |1.783E2| {1.889E-3} 3.725E-4 - \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 68: neg. log cond. likelihood = 101689.80741103672 [71 calls to valueAt]\n",
      "Iter 68 evals 70 <D> [M 1.000E0] 1.017E5 204.98s |1.578E2| {1.672E-3} 3.063E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 69: neg. log cond. likelihood = 101665.61673771383 [72 calls to valueAt]\n",
      "Iter 69 evals 71 <D> [M 1.000E0] 1.017E5 207.80s |1.682E2| {1.782E-3} 2.915E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 70: neg. log cond. likelihood = 101656.49192125817 [73 calls to valueAt]\n",
      "Iter 70 evals 72 <D> [M 1.000E0] 1.017E5 210.69s |3.835E2| {4.064E-3} 2.461E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 71: neg. log cond. likelihood = 101633.53011797438 [74 calls to valueAt]\n",
      "Iter 71 evals 73 <D> [M 1.000E0] 1.016E5 213.76s |1.021E2| {1.083E-3} 2.418E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 72: neg. log cond. likelihood = 101622.86605620365 [75 calls to valueAt]\n",
      "Iter 72 evals 74 <D> [M 1.000E0] 1.016E5 216.60s |1.212E2| {1.284E-3} 2.082E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 73: neg. log cond. likelihood = 101609.74337985278 [76 calls to valueAt]\n",
      "Iter 73 evals 75 <D> [M 1.000E0] 1.016E5 219.49s |1.359E2| {1.441E-3} 1.824E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 74: neg. log cond. likelihood = 101604.53687013635 [77 calls to valueAt]\n",
      "Iter 74 evals 76 <D> [M 1.000E0] 1.016E5 222.36s |2.153E2| {2.282E-3} 1.521E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 75: neg. log cond. likelihood = 101591.87421626883 [78 calls to valueAt]\n",
      "Iter 75 evals 77 <D> [M 1.000E0] 1.016E5 225.21s |5.757E1| {6.101E-4} 1.467E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 76: neg. log cond. likelihood = 101585.96857129059 [79 calls to valueAt]\n",
      "Iter 76 evals 78 <D> [M 1.000E0] 1.016E5 228.08s |8.365E1| {8.865E-4} 1.205E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 77: neg. log cond. likelihood = 101582.56032473422 [80 calls to valueAt]\n",
      "Iter 77 evals 79 <D> [M 1.000E0] 1.016E5 230.97s |2.918E2| {3.092E-3} 1.056E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 78: neg. log cond. likelihood = 101575.11045794492 [81 calls to valueAt]\n",
      "QNMinimizer terminated due to average improvement: | newest_val - previous_val | / |newestVal| < TOL \n",
      "Total time spent in optimization: 233.87s\n",
      "After optimization neg (penalized) log cond likelihood: 101575.11\n",
      "Non-zero parameters: 139746/139746 (100.00%)\n",
      "Checking model correctness; x size 358953 , ysize 19\n",
      "Model is correct [empirical expec = model expec]\n",
      "Saving dictionary of 42269 words ...\n",
      "Extractors list:\n",
      "Extractors[Extractor(-2,word), Extractor(-1,word), Extractor(0,word), Extractor(1,word), Extractor(2,word), ExtractorFrames$ExtractorContinuousTagConjunction(-2,tag), Extractor(-1,tag)]\n",
      "rareExtractors[]\n",
      "Training POS tagger done [265.5 sec].\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "!java -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.MaxentTagger \\\n",
    "    -props french-student.props \n",
    "#     -model 'french-student.tagger' \\\n",
    "#     -testFile 'format=TSV,wordColumn=1,tagColumn=3,fr-ud-dev.conllu3' \\\n",
    "#     -verboseResults false \\\n",
    "#     -iterations 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default properties from tagger french-student.tagger\n",
      "Loading POS tagger from french-student.tagger ... done [0.3 sec].\n",
      "Tagged 10298 words at 7725.43 words per second.\n",
      "Model french-student.tagger has xSize=359188, ySize=19, and numFeatures=170821.\n",
      "Results on 416 sentences and 10298 words, of which 601 were unknown.\n",
      "Total sentences right: 174 (41.826923%); wrong: 242 (58.173077%).\n",
      "Total tags right: 9806 (95.222373%); wrong: 492 (4.777627%).\n",
      "Unknown words right: 412 (68.552413%); wrong: 189 (31.447587%).\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "!java -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.MaxentTagger -model 'french-student.tagger' -testFile 'format=TSV,wordColumn=1,tagColumn=3,fr-ud-test.conllu3' -verboseResults false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default properties from tagger french-student.tagger\n",
      "Loading POS tagger from french-student.tagger ... done [0.2 sec].\n",
      "Tagged 36830 words at 7244.30 words per second.\n",
      "Model french-student.tagger has xSize=359188, ySize=19, and numFeatures=170821.\n",
      "Results on 1478 sentences and 36830 words, of which 2701 were unknown.\n",
      "Total sentences right: 651 (44.046008%); wrong: 827 (55.953992%).\n",
      "Total tags right: 35113 (95.338040%); wrong: 1717 (4.661960%).\n",
      "Unknown words right: 1901 (70.381340%); wrong: 800 (29.618660%).\n"
     ]
    }
   ],
   "source": [
    "!java -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.MaxentTagger -model 'french-student.tagger' -testFile 'format=TSV,wordColumn=1,tagColumn=3,fr-ud-dev.conllu3' -verboseResults false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3 : entraîner un POS tagger pour le français dans NLTK\n",
    "\n",
    "Le but de cette partie est d'utiliser le POS tagger *Averaged Perceptron* de NLTK, en l'entraînant pour le français sur les mêmes données que ci-dessus.  \n",
    "\n",
    "Notez que pour l'anglais, des taggers pré-entraînés sont disponibles dans NLTK, comme expliqué au [Chapitre 5.1 du livre NLTK](http://www.nltk.org/book/ch05.html) : on peut écrire `nltk.pos_tag(sentence)` où *sentence* est une phrase tokenisée. L'étiquetage morpho-syntaxique produira des paires ('mot', 'TAG').\n",
    "\n",
    "**Première étape**\n",
    "\n",
    "Importer les textes annotés `fr-ud-XXXX.conllu3` grâce à des objets `ConllCorpusReader`.  Consultez le mode d'emploi de cette classe directement dans [son code source](https://www.nltk.org/_modules/nltk/corpus/reader/conll.html#ConllCorpusReader), pour déterminer comment lire un fichier en créant un objet `ConllCorpusReader`.  Chargez les trois fichiers, dans trois objets appelés `train_corpus`, `dev_corpus` et `test_corpus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.conll import ConllCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Les', 'DET'), ('commotions', 'NOUN'), ...]\n",
      "[('Aviator', 'PROPN'), (',', 'PUNCT'), ('un', 'DET'), ...]\n",
      "[('Je', 'PRON'), ('sens', 'VERB'), (\"qu'\", 'SCONJ'), ...]\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "root = \".\"\n",
    "\n",
    "train_corpus = ConllCorpusReader(\n",
    "    root, \n",
    "    \"fr-ud-train.conllu3\", \n",
    "    ('ignore', 'words', 'ignore', 'pos'),\n",
    "    separator=\"\\t\"\n",
    ")\n",
    "\n",
    "dev_corpus = ConllCorpusReader(\n",
    "    root, \n",
    "    \"fr-ud-dev.conllu3\", \n",
    "    ('ignore', 'words', 'ignore', 'pos'),\n",
    "    separator=\"\\t\"\n",
    ")\n",
    "\n",
    "test_corpus = ConllCorpusReader(\n",
    "    root, \n",
    "    \"fr-ud-test.conllu3\", \n",
    "    ('ignore', 'words', 'ignore', 'pos'),\n",
    "    separator=\"\\t\"\n",
    ")\n",
    "\n",
    "print(train_corpus.tagged_words())\n",
    "print(dev_corpus.tagged_words())\n",
    "print(test_corpus.tagged_words())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez le nombre de phrases et le nombre de mots de chaque corpus chargé. Cesc chiffres sont-ils identiques à ceux obtenus pour `dev`et pour `test` à la fin de la Partie 1 ?  On peut obtenir les listes de mots étiquetés avec `tagged_words()` et les listes de phrases avec mots étiquetés avec `tagged_sents()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training corpus:\n",
      "Number of words:  366371\n",
      "Number of sentences:  14554\n",
      "\n",
      "Dev corpus:\n",
      "Number of words:  36830\n",
      "Number of sentences:  1478\n",
      "\n",
      "Testing corpus:\n",
      "Number of words:  10298\n",
      "Number of sentences:  416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training corpus:\")\n",
    "print(\"Number of words: \", len(train_corpus.tagged_words()))\n",
    "print(\"Number of sentences: \", len(train_corpus.tagged_sents()))\n",
    "print()\n",
    "print(\"Dev corpus:\")\n",
    "print(\"Number of words: \", len(dev_corpus.tagged_words()))\n",
    "print(\"Number of sentences: \", len(dev_corpus.tagged_sents()))\n",
    "print()\n",
    "print(\"Testing corpus:\")\n",
    "print(\"Number of words: \", len(test_corpus.tagged_words()))\n",
    "print(\"Number of sentences: \", len(test_corpus.tagged_sents()))\n",
    "print()\n",
    "\n",
    "# Nous avons obtenu des chiffres identiques/très proches que précédemment.\n",
    "# La seul différence proviens du nombre de phrases dans les corpus. Nous avons de nouveau une différence de\n",
    "# 1 sur le nombre de phrases. (i.e. la même chose que le tagger de Stanford)\n",
    "#\n",
    "# Comme dit précédemment, nous pensons que cette différence provient de la ligne vide à la fin du document\n",
    "# et que les tagger l'ignore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez la 17e phrase du corpus de développement (avec les étiquettes POS), et les mots 1001 à 1050 du corpus de test (aussi avec leurs POS tags)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17th sentence\n",
      "[('Johnson', 'PROPN'), (\"s'\", 'PRON'), ('appuyait', 'VERB'), ('sur', 'ADP'), ('une', 'DET'), ('unique', 'ADJ'), ('forme', 'NOUN'), ('de', 'ADP'), ('rhétorique', 'NOUN'), (',', 'PUNCT'), ('et', 'CCONJ'), ('sa', 'DET'), ('«', 'PUNCT'), ('réfutation', 'NOUN'), ('»', 'PUNCT'), ('de', 'ADP'), (\"l'\", 'DET'), ('immatérialisme', 'NOUN'), ('de', 'ADP'), ('George', 'PROPN'), ('Berkeley', 'PROPN'), ('est', 'AUX'), ('restée', 'VERB'), ('célèbre', 'ADJ'), (':', 'PUNCT'), ('Berkeley', 'PROPN'), ('affirmait', 'VERB'), ('que', 'SCONJ'), ('la', 'DET'), ('matière', 'NOUN'), (\"n'\", 'ADV'), ('existait', 'VERB'), ('pas', 'ADV'), ('mais', 'CCONJ'), ('semblait', 'VERB'), ('seulement', 'ADV'), ('exister', 'VERB'), (';', 'PUNCT')]\n",
      "\n",
      "Words 1001 to 1050\n",
      "[('la', 'DET'), ('raison', 'NOUN'), ('politique', 'ADJ'), ('...', 'PUNCT'), ('Mais', 'CCONJ'), ('la', 'DET'), ('réalité', 'NOUN'), ('est', 'VERB'), ('que', 'SCONJ'), ('la', 'DET'), ('Mauritanie', 'PROPN'), (\"n'\", 'ADV'), ('est', 'AUX'), ('pas', 'ADV'), ('le', 'DET'), ('Maroc', 'PROPN'), ('ou', 'CCONJ'), (\"l'\", 'DET'), ('Algérie', 'PROPN'), ('.', 'PUNCT'), ('En', 'ADP'), ('Arabie', 'PROPN'), (',', 'PUNCT'), ('on', 'PRON'), ('a', 'VERB'), (\"l'\", 'DET'), ('impression', 'NOUN'), ('que', 'SCONJ'), ('le', 'DET'), ('fondamentalisme', 'NOUN'), ('a', 'AUX'), ('toujours', 'ADV'), ('été', 'VERB'), ('là', 'ADV'), (',', 'PUNCT'), (\"qu'\", 'SCONJ'), ('il', 'PRON'), ('se', 'PRON'), ('maintient', 'VERB'), ('et', 'CCONJ'), (\"n'\", 'ADV'), ('aura', 'VERB'), ('aucun', 'DET'), ('mal', 'NOUN'), ('à', 'ADP'), ('perdurer', 'VERB'), ('.', 'PUNCT'), ('Y', 'PRON'), ('a', 'VERB')]\n"
     ]
    }
   ],
   "source": [
    "# print(\"17th sentence with POS\", dev_corpus.tagged_sents()[17])\n",
    "\n",
    "print(\"17th sentence\")\n",
    "print(dev_corpus.tagged_sents()[17])\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Words 1001 to 1050\")\n",
    "print(test_corpus.tagged_words()[1001:1050])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seconde étape**\n",
    "\n",
    "Vous allez maintenant entraîner (sur le corpus `train`) le POS tagger appelé *Averaged Perceptron* fourni par NLTK mais [implémenté par Mathew Honnibal de Explosion.AI](https://explosion.ai/blog/part-of-speech-pos-tagger-in-python).\n",
    "\n",
    "Dans le [package de NLTK avec des taggers](http://www.nltk.org/api/nltk.tag.html), considérez le module `nltk.tag.perceptron`, pour lequel NLTK explique de façon précise l'entraînement (voir *train the model*) et le test.  Vous allez mettre en oeuvre ces étapes pour entraîner le tagger.  Notez que le modèle est enregistré dans un fichier qui doit finir par `.pickle`, et qui est écrasé à chaque entraînement si vous ne changez pas de nom.  Un modèle peut être également chargé dans un tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os # si nécessaire\n",
    "# import nltk # si nécessaire\n",
    "# nltk.download('averaged_perceptron_tagger') # si nécessaire\n",
    "import time\n",
    "from nltk.tag.perceptron import PerceptronTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptagger = PerceptronTagger(load=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînez ici le tagger sur les données d'entraînement, avec les meilleurs paramètres possibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- staring training ---\n",
      "--- execution time: 117.54656457901001 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "start_time = time.time()\n",
    "\n",
    "corpus = [\n",
    "    [('today','NN'),('is','VBZ'),('good','JJ'),('day','NN')],\n",
    "    [('yes','NNS'),('it','PRP'),('beautiful','JJ')]\n",
    "]\n",
    "print(\"--- staring training ---\")\n",
    "ptagger.train(train_corpus.tagged_sents(), save_loc=\"training_result.pickle\")\n",
    "print(\"--- execution time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combien de temps prend l'entraînement ?  Quelle est la taille du fichier modèle résultant ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution time: ~117 seconds\n",
    "# Generated file size: 6.1MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Évaluez le tagger, d'abord sur les données `dev` puis sur les données `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating tagger on dev data:\n",
      "------------------------------\n",
      "Score:  0.9657073038284008\n",
      "\n",
      "Evaluating tagger on test data:\n",
      "------------------------------\n",
      "Score:  0.9583414255195184\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "print(\"Evaluating tagger on dev data:\")\n",
    "print(\"------------------------------\")\n",
    "print(\"Score: \", ptagger.evaluate(dev_corpus.tagged_sents()))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Evaluating tagger on test data:\")\n",
    "print(\"------------------------------\")\n",
    "print(\"Score: \", ptagger.evaluate(test_corpus.tagged_sents()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veuillez remplir le tableau suivant avec la synthèse des résultats.\n",
    "\n",
    "| Corpus | MaxEnt      | MaxEnt   | Avg Perceptron   | \n",
    "|--------|-------------|----------|------------------|\n",
    "| -      | fourni      | entraîné | entraîné         |\n",
    "| dev    |   ~87.86%   |   ..     |  ~96.56%         |\n",
    "| test   |   ~87.00%   |   ..     |  ~95.78%         |\n",
    "\n",
    "**Comment se comparent les deux POS taggers sur le français ?  Écrivez vos conclusions dans cette cellule.**  \n",
    "En regardant le tableau ci-dessus, on voit que les deux POS tagger sont plus efficace que celui de `Stanford`. Nous pensons que cette différence et lié à l'entraînement que ces différents tagger on effectués. Celui de `Stanford` est sûrement entraîné pour tagger n'importe quel texte en français (i.e. il est plus générique) tandis que les deux autres, on était entraîné sur des corpus très similaire les uns des autres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin du laboratoire 2  \n",
    "\n",
    "Merci de nettoyer votre feuille, exécuter une dernière fois toutes les instructions, sauvegarder le résultat, et le rendre via Cyberlearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
